{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "## Remi LeBlanc and Max Shinnerl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fastai/fastbook/blob/master/12_nlp_dive.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some info:\n",
    "\n",
    "Original fastai model was pretrained with wiki and finetuned on these african new articles\n",
    "Task to was a binary classification to determine in the tags 'Agribusiness' or 'Food and Agriculture' were in the list of tags for each article. One problem with this was only 3% of the articles had this tag, this made it a bit interesting. Accuracy is not a good metric, used f1/f beta score and precision and recall as our metric.\n",
    "Fastai model performed about 80% recall 60% precision.\n",
    "\n",
    "For our project we can either continue looking for agriculture news articles, becasue then we wont have to do anything with the fastai notebooks, or we can do a multilabel or multiclass somehow. \n",
    "\n",
    "The link above in from the fastai text book and he goes through out to make a lanugage model from scratch in pytorch - we might be able to follow that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How will we compare the models?\n",
    "\n",
    "We can just compare the metrics we chose - precision/recall and f1score.\n",
    "We can talk about how it is harder to build from scratch, but have more flexibility. We should find something to do in the pytorch model that helps our model we couldnt do in fastai. Like perhaps with our unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_0628_fixedwithspace_updated.json has about 100,000 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_0728.json has about 500k with 241k in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_data.json has 5000 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import spacy\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('output_0628_fixedwithspace_updated.json') as json_file:\n",
    "#with open('output_0728.json') as json_file:\n",
    "with open('small_data.json') as json_file:\n",
    "\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = {key:val for key, val in data if type(val) == dict}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = {k:v for k,v in all_articles.items() if v!='Article NA'}\n",
    "all_articles = {k:v for k,v in all_articles.items() if v['language']=='English'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Somalia: Sufi Muslim Leaders Surrender to Government',\n",
       " 'article': ' The leaders of a Sufi Muslim group turned themselves into the custody of the Somali government Saturday after fighting left 22 people dead in central Somalia. Moallim Mohamud Sheikh, the spiritual leader, and Sheikh Mohamed Shakir, the chief of Ahlu-Sunna Wal-Jamaa (ASWJ), are in the custody of the Somali national army in the town of Dhusamareb after the group’s militias were overpowered in a battle with government forces. Dhusamareb is the administrative capital of Galmudug state. \"Our security forces have ended the standoff and disarmed all ASWJ militias,” Osman Isse Nur, the spokesperson of the newly elected president, told VOA. Speaking in a video posted online, ASWJ chief Sheikh Shakir said his group ceded power to the Somali national army. \"We agreed to end the fighting for the sake of the civilians. We agreed to hand over ASWJ militias to the commander general who will, in return, take responsibility for the safety of all our members, including the leader,” Shakir said in the video. At least 22 people were killed in clashes that broke out Thursday night after ASWJ militias fired on a government checkpoint in Dhusamareeb. The fighting continued Friday morning before spreading to the nearby town of Guricel in the Galgadud region. Reports say normalcy returned to Dhusamareb Saturday as residents, who were forced to flee, came back and reopened their businesses. Three rival politicians are claiming to be the leader of Galmudug state. Early this month, the parliament of Galmudug elected Ahmed Abdi Kariye as president. He is a former minister backed by the government. ASWJ chief Sheikh Shakir rejected the action, however, and declared himself president, while former president Ahmed Duale refused to cede power. The Sufi group ASWJ played a pivotal role in the fight against al-Shabab militants, and early this week, a U.S. diplomat said in remarks at the U.N. Security Council briefing that internal rivalries among allies in Somalia could derail the effort to combat al-Qaida-linked insurgents.',\n",
       " 'author': 'By Abdulaziz Osman',\n",
       " 'date': ' 1 March 2020',\n",
       " 'source': 'Voice of America (Washington,\\xa0DC)',\n",
       " 'language': 'English',\n",
       " 'original_url': 'https://www.voanews.com/africa/somalias-sufi-muslim-leaders-surrender-government',\n",
       " 'tags': ['Somalia',\n",
       "  'East Africa',\n",
       "  'Legal Affairs',\n",
       "  'Conflict',\n",
       "  'Arms and Armies'],\n",
       " 'full_story': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles['202003010001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up non-matching column names\n",
    "for k,v in all_articles.items():\n",
    "    # Update tag to tags\n",
    "    t = v.get('tag')\n",
    "    if t:\n",
    "        all_articles[k]['tags'] = t\n",
    "        del all_articles[k]['tag']\n",
    "        \n",
    "    # Update full_story to full\n",
    "    f = v.get('full text')\n",
    "    if str(f)!='None':\n",
    "        all_articles[k]['full_story'] = f\n",
    "        del all_articles[k]['full text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>original_url</th>\n",
       "      <th>tags</th>\n",
       "      <th>full_story</th>\n",
       "      <th>full text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, article, author, date, source, language, original_url, tags, full_story, full text]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(all_articles,orient='index')\n",
    "df[df['full text'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['full text'],axis=1)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['liststring'] = [','.join(map(str, l)) for l in df['tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the articles with agri tags\n",
    "indices = []\n",
    "for i, tags in enumerate(df['liststring']):\n",
    "    if 'Agribusiness' in tags or 'Food and Agriculture' in tags:\n",
    "        indices.append(i)\n",
    "# make column of 0 and 1 in df for appearance of that tag\n",
    "ies = [0]*df.shape[0]\n",
    "for x in indices:\n",
    "    ies[x]+=1\n",
    "df['agri_label'] = ies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['agri_label'] = ies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 5000, 0.0246)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3% of articles have agri/foodag tag\n",
    "sum(df['agri_label']==1), len(df), sum(df['agri_label']==1)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>original_url</th>\n",
       "      <th>tags</th>\n",
       "      <th>full_story</th>\n",
       "      <th>liststring</th>\n",
       "      <th>agri_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202003010001</th>\n",
       "      <td>Somalia: Sufi Muslim Leaders Surrender to Gove...</td>\n",
       "      <td>The leaders of a Sufi Muslim group turned the...</td>\n",
       "      <td>By Abdulaziz Osman</td>\n",
       "      <td>1 March 2020</td>\n",
       "      <td>Voice of America (Washington, DC)</td>\n",
       "      <td>English</td>\n",
       "      <td>https://www.voanews.com/africa/somalias-sufi-m...</td>\n",
       "      <td>[Somalia, East Africa, Legal Affairs, Conflict...</td>\n",
       "      <td>False</td>\n",
       "      <td>Somalia,East Africa,Legal Affairs,Conflict,Arm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202003010002</th>\n",
       "      <td>Libya: UN-Mediated Political Talks on Libya En...</td>\n",
       "      <td>U.N.-mediated political talks aimed at resolv...</td>\n",
       "      <td>By Lisa Schlein</td>\n",
       "      <td>1 March 2020</td>\n",
       "      <td>Voice of America (Washington, DC)</td>\n",
       "      <td>English</td>\n",
       "      <td>https://www.voanews.com/middle-east/un-mediate...</td>\n",
       "      <td>[Libya, Conflict, External Relations, North Af...</td>\n",
       "      <td>False</td>\n",
       "      <td>Libya,Conflict,External Relations,North Africa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202003010003</th>\n",
       "      <td>Nigeria: Obasanjo At 83 - a Leader and His Cou...</td>\n",
       "      <td>\"I don't want to be remembered. I am still he...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1 March 2020</td>\n",
       "      <td>This Day (Lagos)</td>\n",
       "      <td>English</td>\n",
       "      <td>https://www.thisdaylive.com/index.php/2020/03/...</td>\n",
       "      <td>[Nigeria, West Africa, Governance]</td>\n",
       "      <td>False</td>\n",
       "      <td>Nigeria,West Africa,Governance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202003010004</th>\n",
       "      <td>Sudan: Service of 14 Ambassadors, 35 Diplomats...</td>\n",
       "      <td>Khartoum — The Higher Committee for the disma...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>29 February 2020</td>\n",
       "      <td>Sudan News Agency (Khartoum)</td>\n",
       "      <td>English</td>\n",
       "      <td>https://suna-sd.net/en/single?id=561889</td>\n",
       "      <td>[Sudan, East Africa, Governance]</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan,East Africa,Governance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202003010005</th>\n",
       "      <td>Sudan: German President Ends Sudan Visit With ...</td>\n",
       "      <td>Khartoum — German President Frank-Walter Stei...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>29 February 2020</td>\n",
       "      <td>Radio Dabanga (Amsterdam)</td>\n",
       "      <td>English</td>\n",
       "      <td>https://www.dabangasudan.org/en/all-news/artic...</td>\n",
       "      <td>[Sudan, External Relations, East Africa, Gover...</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan,External Relations,East Africa,Governanc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          title  \\\n",
       "202003010001  Somalia: Sufi Muslim Leaders Surrender to Gove...   \n",
       "202003010002  Libya: UN-Mediated Political Talks on Libya En...   \n",
       "202003010003  Nigeria: Obasanjo At 83 - a Leader and His Cou...   \n",
       "202003010004  Sudan: Service of 14 Ambassadors, 35 Diplomats...   \n",
       "202003010005  Sudan: German President Ends Sudan Visit With ...   \n",
       "\n",
       "                                                        article  \\\n",
       "202003010001   The leaders of a Sufi Muslim group turned the...   \n",
       "202003010002   U.N.-mediated political talks aimed at resolv...   \n",
       "202003010003   \"I don't want to be remembered. I am still he...   \n",
       "202003010004   Khartoum — The Higher Committee for the disma...   \n",
       "202003010005   Khartoum — German President Frank-Walter Stei...   \n",
       "\n",
       "                          author              date  \\\n",
       "202003010001  By Abdulaziz Osman      1 March 2020   \n",
       "202003010002     By Lisa Schlein      1 March 2020   \n",
       "202003010003                 N/A      1 March 2020   \n",
       "202003010004                 N/A  29 February 2020   \n",
       "202003010005                 N/A  29 February 2020   \n",
       "\n",
       "                                         source language  \\\n",
       "202003010001  Voice of America (Washington, DC)  English   \n",
       "202003010002  Voice of America (Washington, DC)  English   \n",
       "202003010003                   This Day (Lagos)  English   \n",
       "202003010004       Sudan News Agency (Khartoum)  English   \n",
       "202003010005          Radio Dabanga (Amsterdam)  English   \n",
       "\n",
       "                                                   original_url  \\\n",
       "202003010001  https://www.voanews.com/africa/somalias-sufi-m...   \n",
       "202003010002  https://www.voanews.com/middle-east/un-mediate...   \n",
       "202003010003  https://www.thisdaylive.com/index.php/2020/03/...   \n",
       "202003010004            https://suna-sd.net/en/single?id=561889   \n",
       "202003010005  https://www.dabangasudan.org/en/all-news/artic...   \n",
       "\n",
       "                                                           tags full_story  \\\n",
       "202003010001  [Somalia, East Africa, Legal Affairs, Conflict...      False   \n",
       "202003010002  [Libya, Conflict, External Relations, North Af...      False   \n",
       "202003010003                 [Nigeria, West Africa, Governance]      False   \n",
       "202003010004                   [Sudan, East Africa, Governance]      False   \n",
       "202003010005  [Sudan, External Relations, East Africa, Gover...      False   \n",
       "\n",
       "                                                     liststring  agri_label  \n",
       "202003010001  Somalia,East Africa,Legal Affairs,Conflict,Arm...           0  \n",
       "202003010002  Libya,Conflict,External Relations,North Africa...           0  \n",
       "202003010003                     Nigeria,West Africa,Governance           0  \n",
       "202003010004                       Sudan,East Africa,Governance           0  \n",
       "202003010005  Sudan,External Relations,East Africa,Governanc...           0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will build a language model from the 'article' column to predict the 'agri_label' column or the 'tags' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load information about words\n",
    "#!python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de640aabd19044e8b2c3b369ab0a069c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "max_length: 3575\n"
     ]
    }
   ],
   "source": [
    "# \"article\" column has article text\n",
    "# Let's make new column with title and article text appended + tokenized and cleaned.\n",
    "# also get max article length while we're here, for padding later\n",
    "import re\n",
    "combined_clean = []\n",
    "max_length = 0\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    row = df.iloc[i].copy()\n",
    "    combined = row['title'] + ' ' + row['article']\n",
    "    combined = re.sub(\"[^A-Za-z']+\", ' ', combined).lower()\n",
    "    combined = nlp(combined)\n",
    "    combined = [token.lemma_ for token in combined if ((not token.is_stop) or (' ' in token.text))]\n",
    "    if len(combined) > 1:\n",
    "        if len(combined) > max_length:\n",
    "            max_length = len(combined)\n",
    "        cleaned = ' '.join(combined)\n",
    "    combined_clean.append(cleaned)\n",
    "\n",
    "df['cleaned'] = combined_clean\n",
    "df.to_csv('cleaned.csv')\n",
    "print('max_length:', max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### re-read clean data and let's begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv('cleaned.csv')\n",
    "df_clean.columns\n",
    "max_length=3575 # calculated above, hardcoded here to avoid running long code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48338"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = [article.split(' ') for article in list(df_clean['cleaned'])]\n",
    "word_freq = dict(Counter([token for text in articles for token in text]).most_common())\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14423"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq = 5  # word must appear at least min_freq times to get it's own token\n",
    "\n",
    "word2idx = {}\n",
    "i = 0  # leave 0 for unknowns/infrequents\n",
    "for word in word_freq:\n",
    "    if word_freq[word] > min_freq:\n",
    "        word2idx[word] = i\n",
    "        i += 1\n",
    "    else:\n",
    "        word2idx[word] = 0\n",
    "\n",
    "vocab_length = max(word2idx.values()) + 1\n",
    "vocab_length  # essentially number of all unique words excluding infrequents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   0,    0,    0,  ..., 6501,  806, 1627]), tensor(0.))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ArticleDataset(Dataset):\n",
    "    def __init__(self, df, word_dict, max_length):\n",
    "        self.df = df\n",
    "        self.word_dict = word_dict\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.df))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx].copy()\n",
    "        \n",
    "        article = row['cleaned'].split(' ')\n",
    "        x = torch.zeros(self.max_length)\n",
    "        for i in range(len(article)):\n",
    "            # front pad\n",
    "            x[self.max_length - len(article) + i] = self.word_dict[article[i]]\n",
    "            \n",
    "        y = torch.tensor(row['agri_label'])\n",
    "        \n",
    "        return x.long(), y.float()\n",
    "\n",
    "ds = ArticleDataset(df_clean, word2idx, max_length)\n",
    "next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data loaders\n",
    "batch_size = 100\n",
    "\n",
    "train_df, valid_df = train_test_split(df_clean, test_size=0.2)\n",
    "\n",
    "train_ds = ArticleDataset(train_df, word2idx, max_length)\n",
    "valid_ds = ArticleDataset(valid_df, word2idx, max_length)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel1(nn.Module):\n",
    "    def __init__(self, vocab_size=vocab_length, hidden_size=50):\n",
    "        super(RNNModel1, self).__init__()\n",
    "        self.i_h = nn.Embedding(vocab_size, hidden_size)  \n",
    "        self.h_h = nn.Linear(hidden_size, hidden_size)     \n",
    "        self.h_o = nn.Linear(hidden_size, 1)\n",
    "        self.h = 0\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i in range(3):\n",
    "            self.h = self.h + self.i_h(x[:,i])\n",
    "            self.h = self.h_h(self.h)\n",
    "        out = self.h_o(self.h)\n",
    "        self.h = self.h.detach()\n",
    "        return out.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel2(nn.Module):\n",
    "    def __init__(self, vocab_size=vocab_length, embedding_size=50):\n",
    "        super(RNNModel2, self).__init__()\n",
    "        self.word_emb = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
    " \n",
    "        self.rnn = nn.RNN(input_size=embedding_size, hidden_size=1, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.word_emb(x)\n",
    "\n",
    "        x = self.rnn(x)[1]\n",
    "    \n",
    "        return torch.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b233196238b439a8dd5a14454b49a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e441ac13c151417aae951994f1d85732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 0 avg_loss: 0.2204151235637255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b04c17ab57f40cd93213c53da058ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1 avg_loss: 0.1174587975256145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdec21a3bf24a45b5c81198521519f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2 avg_loss: 0.11634211838245392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7607d07ebba24456853f0e4720bd8aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3 avg_loss: 0.11704528140835464\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b894b9389914abe9ba53e33f6ebd1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4 avg_loss: 0.11682993597351014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's train\n",
    "epochs = 5\n",
    "model1_rnn = RNNModel1()\n",
    "lossFun = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model1_rnn.parameters(), lr = 0.001)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    total_loss = 0.0\n",
    "    model1_rnn.train()\n",
    "    for x, y in tqdm(train_dl):\n",
    "        yhat = model1_rnn(x)\n",
    "        loss = lossFun(yhat, y)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dl)\n",
    "    print('epoch:', epoch, 'avg_loss:', avg_loss)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224a59f047d5432283029d513d9432ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e979dc2a8c4e299debf84c3c05f102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 0 avg_loss: 0.8319368928670883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a61509c527487081cc08ed6a53565b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1 avg_loss: 0.794037775695324\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e76cdbb8d046a5835f873e41b9be1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2 avg_loss: 0.7512031868100166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21954a220a0e47eabfe52c198829421c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3 avg_loss: 0.7021968856453895\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6e3474f9e14c83955c5f3ebd615cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4 avg_loss: 0.6514816924929618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's train\n",
    "epochs = 5\n",
    "model2_rnn = RNNModel2()\n",
    "lossFun = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model2_rnn.parameters(), lr = 0.001)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    total_loss = 0.0\n",
    "    model2_rnn.train()\n",
    "    for x, y in tqdm(train_dl):\n",
    "        yhat = model2_rnn(x)\n",
    "        loss = lossFun(yhat, y)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dl)\n",
    "    print('epoch:', epoch, 'avg_loss:', avg_loss)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision and recall:\n",
    "Precision = True Positives / (True Positives + False Positives)\n",
    "\n",
    "Recall = True Postivies / (True Positives + False Negatives)\n",
    "\n",
    "Reason: Significantly fewer agriculture articles compared to others, don't really care about True Negatives (i.e. y and yhat both 0)\n",
    "\n",
    "We want to emphasize guessing the agriculture ones correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(ytrues, ypreds):\n",
    "    assert(len(ytrues) == len(ypreds))\n",
    "    \n",
    "    # don't need all of these, tracking just in case\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    N = len(ytrues)\n",
    "    \n",
    "    for ytrue, ypred in zip(ytrues, ypreds):\n",
    "        \n",
    "        if   ytrue == 1 and ypred == 1:\n",
    "            TP += 1\n",
    "        elif ytrue == 0 and ypred == 1:\n",
    "            FP += 1\n",
    "        elif ytrue == 1 and ypred == 0:\n",
    "            FN += 1\n",
    "        elif ytrue == 0 and ypred == 0:\n",
    "            TN += 1\n",
    "        else:\n",
    "            print('bad input, not ones and zeroes')\n",
    "            break\n",
    "    \n",
    "    if TP == 0:\n",
    "        return (0,0)\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall    = TP / (TP + FN)\n",
    "    \n",
    "    return (precision,recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_prediction(x, model, threshold=0.01):\n",
    "    model.eval()\n",
    "    return (torch.sigmoid(model(x)) > threshold).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_ypreds_rnn = []\n",
    "model2_ypreds_rnn = []\n",
    "ytrues_rnn        = []\n",
    "\n",
    "for x, y in valid_dl:\n",
    "    \n",
    "    ytrues_rnn += list(y)\n",
    "    model1_ypreds_rnn += list(get_binary_prediction(x, model1_rnn))\n",
    "    model2_ypreds_rnn += list(get_binary_prediction(x, model2_rnn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.024, 1.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall(ytrues_rnn, model1_ypreds_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.024, 1.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall(ytrues_rnn, model2_ypreds_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model 1\n",
    "class LSTMModel1(nn.Module):\n",
    "    def __init__(self,\n",
    "                 batch_size,\n",
    "                 vocab_size=vocab_length,\n",
    "                 hidden_size=50):\n",
    "        \n",
    "        super(LSTMModel1, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.h2o = nn.Linear(hidden_size, 1)  # binary classification\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        emb = self.emb(x)\n",
    "        out, hidden = self.lstm(emb)\n",
    "        \n",
    "        # many to one, so final hidden state through linear layer\n",
    "        final = torch.squeeze(hidden[-1].permute((1,2,0)))\n",
    "        final = self.h2o(final)\n",
    "        \n",
    "        \n",
    "        return(torch.squeeze(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model 2 -- dropout layer added\n",
    "class LSTMModel2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 batch_size,\n",
    "                 vocab_size=vocab_length,\n",
    "                 hidden_size=50,\n",
    "                 p=0.5\n",
    "                ):\n",
    "        \n",
    "        super(LSTMModel2, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.h2o = nn.Linear(hidden_size, 1)  # binary classification\n",
    "        \n",
    "        self.dropout = nn.Dropout(p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        emb = self.emb(x)\n",
    "        out, hidden = self.lstm(emb)\n",
    "        \n",
    "        final = torch.squeeze(hidden[-1].permute((1,2,0)))\n",
    "        \n",
    "        final = self.dropout(final)\n",
    "        \n",
    "        final = self.h2o(final)\n",
    "        \n",
    "        return(torch.squeeze(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc1261347d54115b40bd79683066897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f520d902b4184e6cbe738295bcea22e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 0 avg_loss: 0.4460502710193396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27de422dedb54a99925134129844382e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1 avg_loss: 0.12852044766768814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fecb5c99bf6d4a0aa19135c6ab69ab03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2 avg_loss: 0.11184826488606632\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4fa8ef56dd48a29eb27df1bef1bc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3 avg_loss: 0.10404208078980445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0912dc198f604f5ab64ce4d1e38cd325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4 avg_loss: 0.09463547193445265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train LSTM 1\n",
    "epochs = 5\n",
    "model1_lstm = LSTMModel1(batch_size)\n",
    "lossFun = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model1_lstm.parameters(), lr = 0.001)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    total_loss = 0.0\n",
    "    model1_lstm.train()\n",
    "    for x, y in tqdm(train_dl):\n",
    "        yhat = model1_lstm(x)\n",
    "        \n",
    "        loss = lossFun(yhat, y)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dl)\n",
    "    print('epoch:', epoch, 'avg_loss:', avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752713a64da54e0687766a24ea7b9458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39fb764706f49dd9e8f475c68095c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 0 avg_loss: 0.46490304078906775\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f871a27c4648348423efc042d05846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1 avg_loss: 0.13312433022074402\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1e1be15e6d447e960c902638e18428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2 avg_loss: 0.11384900910779834\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296f9b812e3844b7b0f22f09c427c72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3 avg_loss: 0.10714390901848674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f40db4eb5d441b87153a180675cb04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4 avg_loss: 0.09489621040411293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train lstm 2\n",
    "epochs = 5\n",
    "model2_lstm = LSTMModel2(batch_size)\n",
    "lossFun = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model2_lstm.parameters(), lr = 0.001)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    total_loss = 0.0\n",
    "    model2_lstm.train()\n",
    "    for x, y in tqdm(train_dl):\n",
    "        yhat = model2_lstm(x)\n",
    "        \n",
    "        loss = lossFun(yhat, y)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dl)\n",
    "    print('epoch:', epoch, 'avg_loss:', avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_ypreds_lstm = []\n",
    "model2_ypreds_lstm = []\n",
    "ytrues_lstm        = []\n",
    "\n",
    "for x, y in valid_dl:\n",
    "    \n",
    "    ytrues_lstm += list(y)\n",
    "    model1_ypreds_lstm += list(get_binary_prediction(x, model1_lstm))\n",
    "    model2_ypreds_lstm += list(get_binary_prediction(x, model2_lstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.032432432432432434, 0.75)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall(ytrues_lstm, model1_ypreds_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03355704697986577, 0.625)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall(ytrues_lstm, model2_ypreds_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Performance:\n",
    "RNN Model 1 precision, recall:  (0.024, 1.0)\n",
    "\n",
    "RNN Model 2 precision, recall:  (0.024, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Performance:\n",
    "LSTM Model 1 precision, recall: (0.032, 0.75)\n",
    "\n",
    "LSTM Model 2 precision, recall: (0.034, 0.625)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai model performance:\n",
    "For the fastai it was 60% precision, 80% recall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
